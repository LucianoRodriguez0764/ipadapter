{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LucianoRodriguez0764/ipadapter/blob/main/Ipadapter_faceID_Latest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing dependencies and download the IP-Adapter model"
      ],
      "metadata": {
        "id": "OB5WejBfJtq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install insightface\n",
        "!pip install onnxruntime\n",
        "!pip install diffusers\n",
        "!pip install git+https://github.com/tencent-ailab/IP-Adapter.git\n",
        "!pip install einops"
      ],
      "metadata": {
        "id": "MQzuaaeAThi1",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O ip-adapter-faceid_sd15.bin https://huggingface.co/h94/IP-Adapter-FaceID/resolve/main/ip-adapter-faceid_sd15.bin?download=true"
      ],
      "metadata": {
        "id": "UG-sgicMIUKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the pipe, vae and noise scheduler for IP-Adapter"
      ],
      "metadata": {
        "id": "SPhrv6tgJ3Gl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from diffusers import StableDiffusionPipeline, DDIMScheduler, AutoencoderKL, AutoPipelineForText2Image\n",
        "from PIL import Image\n",
        "\n",
        "from ip_adapter.ip_adapter_faceid import IPAdapterFaceID\n",
        "\n",
        "base_model_path = \"SG161222/Realistic_Vision_V4.0_noVAE\"\n",
        "#new model\n",
        "base_model_path = \"SG161222/Realistic_Vision_V6.0_B1_noVAE\"\n",
        "vae_model_path = \"stabilityai/sd-vae-ft-mse\"\n",
        "ip_ckpt = \"ip-adapter-faceid_sd15.bin\"\n",
        "device = \"cuda\"\n",
        "\n",
        "noise_scheduler = DDIMScheduler(\n",
        "    num_train_timesteps=1000,\n",
        "    beta_start=0.00085,\n",
        "    beta_end=0.012,\n",
        "    beta_schedule=\"scaled_linear\",\n",
        "    clip_sample=False,\n",
        "    set_alpha_to_one=False,\n",
        "    steps_offset=1,\n",
        ")\n",
        "vae = AutoencoderKL.from_pretrained(vae_model_path).to(dtype=torch.float16)\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    base_model_path,\n",
        "    torch_dtype=torch.float16,\n",
        "    scheduler=noise_scheduler,\n",
        "    vae=vae,\n",
        "    feature_extractor=None,\n",
        "    safety_checker=None\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rKFbQ0L3Zww0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading face analysis app and face embeddings"
      ],
      "metadata": {
        "id": "TKIdqZApJD8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import cv2\n",
        "from insightface.app import FaceAnalysis\n",
        "\n",
        "\n",
        "app = FaceAnalysis(name=\"buffalo_l\", providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])\n",
        "app.prepare(ctx_id=0, det_size=(640, 640))"
      ],
      "metadata": {
        "id": "qVo-MJULJAxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "\n",
        "# Set the directory containing images\n",
        "image_path = 'images/face'\n",
        "\n",
        "imgs = glob.glob(os.path.join(image_path, '*.*'))\n",
        "#imgs += glob.glob(os.path.join('images/face_2', '*.*'))\n",
        "#imgs += glob.glob(os.path.join('images/face_3', '*.*'))\n",
        "\n",
        "# Collect all embeddings\n",
        "embeddings = []\n",
        "\n",
        "for i in range(len(imgs)):\n",
        "    print(imgs[i])\n",
        "    image = cv2.imread(imgs[i])\n",
        "    faces = app.get(image)\n",
        "\n",
        "    # Check if a face is detected\n",
        "    if faces:\n",
        "        faceid_embed = torch.from_numpy(faces[0].normed_embedding).unsqueeze(0)\n",
        "        embeddings.append(faceid_embed)\n",
        "    else:\n",
        "        print(\"face not detected\")\n",
        "\n",
        "# Calculate the average embedding for the face ID\n",
        "\n",
        "weights = []\n",
        "weights = [elem/sum(weights) for elem in weights]\n",
        "#print(weights)\n",
        "\n",
        "if embeddings:\n",
        "\n",
        "    ### weights\n",
        "    total = torch.zeros_like(embeddings[0])\n",
        "    for i in range(len(embeddings)):\n",
        "        if len(weights)==len(embeddings):\n",
        "            total.add_(embeddings[i]*weights[i])\n",
        "        else:\n",
        "            total.add_(embeddings[i]*(1/len(embeddings)))\n",
        "    faceid_embeds = total / len(embeddings[i])\n",
        "\n",
        "    ###  mean weights\n",
        "    #faceid_embeds = torch.mean(torch.stack(embeddings), dim=0)\n",
        "\n",
        "    print(\"Collected face ID embedding\")\n",
        "else:\n",
        "    print(\"No faces detected in the images provided.\")\n"
      ],
      "metadata": {
        "id": "UZyr305nkyuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate the image with IP-Adapter"
      ],
      "metadata": {
        "id": "VtB54JeMJT_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "from ipywidgets import HBox, Image\n",
        "import random\n",
        "\n",
        "def display_images(images, format=\"png\"):\n",
        "  # Assuming images is a list of PIL Images\n",
        "  if format==\"png\" or True:\n",
        "    image_widgets = [Image(value=img._repr_png_()) for img in images]\n",
        "  # Display the images in a row\n",
        "  display(HBox(image_widgets))\n",
        "\n",
        "# load ip-adapter\n",
        "ip_model = IPAdapterFaceID(pipe, ip_ckpt, device)\n",
        "ip_model.set_scale(1)\n",
        "\n",
        "prompt = \"\"\n",
        "prompt += \"photo of a 20 years old girl\"\n",
        "extra_prompt = \"\"\n",
        "\n",
        "negative_prompt = \"(deformed iris, deformed pupils, semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, anime), text, cropped, out of frame, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, nfsw, extra legs, fused fingers, too many fingers, long neck\"\n",
        "negative_prompt += \"\"\n",
        "\n",
        "width = 512\n",
        "height = 512\n",
        "num_inference_steps = 50\n",
        "guidance_scale = 4\n",
        "num_samples = 1\n",
        "random_seed = 7030977\n",
        "use_hardcoded_seed = False\n",
        "\n",
        "\n",
        "x_plot_generation = True\n",
        "y_plot_generation = True\n",
        "x_plot_parameter = 'num_inference_steps'\n",
        "x_plot_values = [30,50,70]\n",
        "y_plot_parameter = 'extra_prompt'\n",
        "y_plot_values = [\"wearing blue and cyan dress, bun hair\",\"wearing black and gold dress, ponytail hair\"]\n",
        "xy_different_seeds = False\n",
        "\n",
        "if not use_hardcoded_seed:\n",
        "  random_seed = random.randint(1, 9999999)\n",
        "\n",
        "if x_plot_generation:\n",
        "  num_samples=1\n",
        "  if y_plot_generation:\n",
        "    images_array = []\n",
        "    for h in range(len(y_plot_values)):\n",
        "      images = []\n",
        "      if y_plot_parameter in globals():\n",
        "        globals()[y_plot_parameter] = y_plot_values[h]\n",
        "        print(y_plot_parameter,\"set to:\",y_plot_values[h])\n",
        "      for i in range(len(x_plot_values)):\n",
        "        if x_plot_parameter in globals():\n",
        "          globals()[x_plot_parameter] = x_plot_values[i]\n",
        "          print(x_plot_parameter,\"set to:\",x_plot_values[i])\n",
        "        if xy_different_seeds and i!=0:\n",
        "          random_seed = random.randint(1, 9999999)\n",
        "        print(\"Seed: \", random_seed)\n",
        "        generated_image = ip_model.generate(\n",
        "            prompt=prompt+\", \"+extra_prompt, negative_prompt=negative_prompt, faceid_embeds=faceid_embeds, num_samples=num_samples, width=width, height=height, num_inference_steps=num_inference_steps, seed=random_seed,\n",
        "            guidance_scale=guidance_scale\n",
        "        )[0]\n",
        "        images.append(generated_image)\n",
        "      images_array.append(images)\n",
        "    for img in images_array:\n",
        "      display_images(img)\n",
        "  elif x_plot_generation:\n",
        "    images = []\n",
        "    for i in range(len(x_plot_values)):\n",
        "      if x_plot_parameter in globals():\n",
        "        globals()[x_plot_parameter] = x_plot_values[i]\n",
        "        print(x_plot_parameter,\"set to:\",x_plot_values[i])\n",
        "      if xy_different_seeds and i!=0:\n",
        "        random_seed = random.randint(1, 9999999)\n",
        "      print(\"Seed: \", random_seed)\n",
        "      images.extend(ip_model.generate(\n",
        "          prompt=prompt+\", \"+extra_prompt, negative_prompt=negative_prompt, faceid_embeds=faceid_embeds, num_samples=num_samples, width=width, height=height, num_inference_steps=num_inference_steps, seed=random_seed,\n",
        "          guidance_scale=guidance_scale\n",
        "      ))\n",
        "    display_images(images)\n",
        "\n",
        "\n",
        "else:\n",
        "\n",
        "  print(\"Seed: \", random_seed)\n",
        "  images = ip_model.generate(\n",
        "      prompt=prompt+\", \"+extra_prompt, negative_prompt=negative_prompt, faceid_embeds=faceid_embeds, num_samples=num_samples, width=width, height=height, num_inference_steps=num_inference_steps, seed=random_seed,\n",
        "      guidance_scale=guidance_scale\n",
        "  )\n",
        "\n",
        "  display_images(images)\n",
        "\n"
      ],
      "metadata": {
        "id": "qRYVP7maJRWL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}